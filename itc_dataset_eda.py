# -*- coding: utf-8 -*-
"""ITC Dataset EDA

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/12uTML0dRH3P8rcuqQcT5WvvKxKszo9gM
"""

from pyspark.sql import SparkSession
from pyspark.sql.functions import col, lag
spark = SparkSession.builder.appName("ITC dataset").getOrCreate()

from google.colab import drive
drive.mount('/content/drive')

df_itc = spark.read.format("csv").option("header","True").option("inferSchema","True").load("/content/drive/MyDrive/ITC-DatasetEDA /ITC.csv")

df_itc.show()

cleaned_df = df_itc.dropna()

print(df_itc.columns)

df_cleaned  = df_itc.filter((col("Price").isNotNull()) & (col("Adj Close").isNotNull()) & (col("Close").isNotNull()) & (col("High").isNotNull())& (col("Low").isNotNull())& (col("Open").isNotNull())& (col("Volume").isNotNull()))

df_cleaned.show()

df_cleaned = spark.createDataFrame(df_cleaned.tail(df_cleaned.count() - 1), schema=df_cleaned.schema)

df_cleaned.show()

df_cleaned = df_cleaned.withColumnRenamed("Price", "Date")

df_cleaned.show()

df_cleaned = df_cleaned.withColumnRenamed("Adj Close", "Adj_Close")

df_cleaned.show()

df_cleaned.printSchema()

df_cleaned.count()

df_cleaned.show(7250)

df_cleaned.coalesce(1).write.format("csv").option("header", "true").mode("overwrite").save("/content/drive/MyDrive/ITC-DatasetEDA ")

itc = spark.read.format("csv").option("header","True").option("inferSchema","True").load("/content/drive/MyDrive/ITC-DatasetEDA /ITC-cleaneddata.csv")

itc.registerTempTable("ITC_Stock")

itc.show()

from pyspark.sql.functions import year, month

#2. Day with Highest Adj_Close Price:

df_adjClose = spark.sql("SELECT Date, Adj_Close FROM ITC_Stock ORDER BY Adj_Close DESC LIMIT 1;").show()

#3. Day with Lowest Adj_Close Price:
df_lowAdj = spark.sql("SELECT Date, Adj_Close FROM ITC_Stock ORDER BY Adj_Close ASC LIMIT 1;").show()

#4. Average Daily Trading Volume:
df_daily = spark.sql("SELECT AVG(Volume) AS Avg_Daily_Volume FROM ITC_Stock;").show()

#5. Day with Highest Volume:
df_day = spark.sql("SELECT Date, Volume, Adj_Close FROM ITC_Stock ORDER BY Volume DESC LIMIT 1;").show()

#6. Trends in Monthly/Yearly Average Volume:
df_month = spark.sql("SELECT YEAR(Date) AS Year, MONTH(Date) AS Month, AVG(Volume) AS Avg_Volume FROM ITC_Stock GROUP BY YEAR(Date), MONTH(Date) ORDER BY Year, Month;").show()

#7. Correlation Between Volume and Daily Adj_Close Change:
df_vol=spark.sql("WITH DailyChanges AS (SELECT Date, Volume, Adj_Close, LAG(Adj_Close) OVER (ORDER BY Date) AS Prev_Adj_Close FROM ITC_Stock) SELECT CORR(Volume, Adj_Close - Prev_Adj_Close) AS Volume_AdjClose_Correlation FROM DailyChanges;").show()

#8. Days with Adj_Close > Open:
df_open = spark.sql("SELECT COUNT(*) AS Days_AdjClose_Higher FROM ITC_Stock WHERE Adj_Close > Open;").show()

#9. Days with Adj_Close < Open:
df_close = spark.sql("SELECT COUNT(*) AS Days_AdjClose_Lower FROM ITC_Stock WHERE Adj_Close < Open;").show()

#10. Average Daily Volatility:
df_volt = spark.sql("SELECT AVG(High - Low) AS Avg_Daily_Volatility FROM ITC_Stock;").show()

#11. Day with Highest Volatility:

df_highVolt = spark.sql("SELECT Date, High, Low, (High - Low) AS Volatility FROM ITC_Stock ORDER BY Volatility DESC LIMIT 1;").show()

#12. Average Monthly Returns:
df_monthly = spark.sql("SELECT YEAR(Date) AS Year, MONTH(Date) AS Month, (MAX(Adj_Close) - MIN(Adj_Close)) / MIN(Adj_Close) * 100 AS Monthly_Return FROM ITC_Stock GROUP BY YEAR(Date), MONTH(Date) ORDER BY Year, Month;").show()

#13. Performance by Month/Quarter:
df_quat = spark.sql("SELECT MONTH(Date) AS Month, QUARTER(Date) AS Quarter, AVG(Adj_Close) AS Avg_Adj_Close, AVG(High - Low) AS Avg_Volatility FROM ITC_Stock GROUP BY MONTH(Date), QUARTER(Date) ORDER BY Month;").show()

#14. Average Adj_Close Price Per Year:
df_adjClose = spark.sql("SELECT YEAR(Date) AS Year, AVG(Adj_Close) AS Avg_Adj_Close FROM ITC_Stock GROUP BY YEAR(Date) ORDER BY Year;").show()

#15. Stock Behavior During Pandemic (2020â€“2021):
df_pand = spark.sql("SELECT YEAR(Date) AS Year, MONTH(Date) AS Month, AVG(Adj_Close) AS Avg_Adj_Close, AVG(High - Low) AS Avg_Volatility, AVG(Volume) AS Avg_Volume FROM ITC_Stock WHERE YEAR(Date) BETWEEN 2020 AND 2021 GROUP BY YEAR(Date), MONTH(Date) ORDER BY Year, Month;").show()

#16. Volume and Volatility During Major Events:
df_volatility = spark.sql("SELECT Date, Adj_Close, Volume, (High - Low) AS Volatility FROM ITC_Stock WHERE YEAR(Date) BETWEEN 2020 AND 2021 ORDER BY Date;").show()

#17. Standard Deviation of Daily Adj_Close Prices:
df_std = spark.sql("SELECT STDDEV(Adj_Close) AS StdDev_Adj_Close FROM ITC_Stock;").show()

#18. Average Percentage Change Between Open and Adj_Close:
df_perc = spark.sql("SELECT AVG((Adj_Close - Open) / Open * 100) AS Avg_Percentage_Change FROM ITC_Stock;").show()

#19. Bullish vs Bearish Days:
df_bull = spark.sql("SELECT COUNT(CASE WHEN Adj_Close > Open THEN 1 END) AS Bullish_Days, COUNT(CASE WHEN Adj_Close < Open THEN 1 END) AS Bearish_Days FROM ITC_Stock;").show()

#20. Best Months or Quarters for Investment:

df_Months = spark.sql("SELECT MONTH(Date) AS Month, QUARTER(Date) AS Quarter, AVG(Adj_Close) AS Avg_Adj_Close FROM ITC_Stock GROUP BY MONTH(Date), QUARTER(Date) ORDER BY Avg_Adj_Close DESC;").show()

import pandas as pd
import matplotlib.pyplot as plt

# Load the data from the provided CSV file
file_path = '/content/drive/MyDrive/ITC-DatasetEDA /ITC-cleaneddata.csv'
df = pd.read_csv(file_path)

# Convert Date to datetime format
df['Date'] = pd.to_datetime(df['Date'])

# Plotting the overall trend of Adjusted Close prices
plt.figure(figsize=(10, 6))
plt.plot(df['Date'], df['Adj_Close'], label='Adjusted Close Price', color='blue')
plt.title('Overall Trend of ITC\'s Adjusted Close Price')
plt.xlabel('Date')
plt.ylabel('Adjusted Close Price (INR)')
plt.grid(True)
plt.legend()
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

# Plotting the monthly average of Adjusted Close Price
df['Year-Month'] = df['Date'].dt.to_period('M')
monthly_avg = df.groupby('Year-Month')['Adj_Close'].mean()

plt.figure(figsize=(10, 6))
monthly_avg.plot(kind='line', color='green')
plt.title('Monthly Average Adjusted Close Price')
plt.xlabel('Month')
plt.ylabel('Average Adjusted Close Price (INR)')
plt.grid(True)
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

# Plotting the yearly average of Adjusted Close Price
df['Year'] = df['Date'].dt.year
yearly_avg = df.groupby('Year')['Adj_Close'].mean()

plt.figure(figsize=(10, 6))
yearly_avg.plot(kind='bar', color='orange')
plt.title('Yearly Average Adjusted Close Price')
plt.xlabel('Year')
plt.ylabel('Average Adjusted Close Price (INR)')
plt.grid(True)
plt.tight_layout()
plt.show()

# Plotting the volume over time
plt.figure(figsize=(10, 6))
plt.plot(df['Date'], df['Volume'], label='Volume', color='red')
plt.title('Volume Traded Over Time')
plt.xlabel('Date')
plt.ylabel('Volume Traded')
plt.grid(True)
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()